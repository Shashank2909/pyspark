{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe18d441",
   "metadata": {},
   "source": [
    "# # RDD operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e73f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40c21d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/spark\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ['SPARK_HOME'])\n",
    "#print(os.environ['JAVA_HOME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117e856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45a4ba7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/shashank/env/lib/python3.8/site-packages/pyspark'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26d44cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f5c7d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "726965b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName(\"newApp\").setMaster(\"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "25268662",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a721bb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "90c2078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e0c66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.getConf().get('spark.eventLog.dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a77bfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[',ID,Name,Age,Photo,Nationality,Flag,Overall,Potential,Club,Club Logo,Value,Wage,Special,Preferred Foot,International Reputation,Weak Foot,Skill Moves,Work Rate,Body Type,Real Face,Position,Jersey Number,Joined,Loaned From,Contract Valid Until,Height,Weight,LS,ST,RS,LW,LF,CF,RF,RW,LAM,CAM,RAM,LM,LCM,CM,RCM,RM,LWB,LDM,CDM,RDM,RWB,LB,LCB,CB,RCB,RB,Crossing,Finishing,HeadingAccuracy,ShortPassing,Volleys,Dribbling,Curve,FKAccuracy,LongPassing,BallControl,Acceleration,SprintSpeed,Agility,Reactions,Balance,ShotPower,Jumping,Stamina,Strength,LongShots,Aggression,Interceptions,Positioning,Vision,Penalties,Composure,Marking,StandingTackle,SlidingTackle,GKDiving,GKHandling,GKKicking,GKPositioning,GKReflexes,Release Clause',\n",
       " '0,158023,L. Messi,31,https://cdn.sofifa.org/players/4/19/158023.png,Argentina,https://cdn.sofifa.org/flags/52.png,94,94,FC Barcelona,https://cdn.sofifa.org/teams/2/light/241.png,€110.5M,€565K,2202,Left,5,4,4,Medium/ Medium,Messi,Yes,RF,10,\"Jul 1, 2004\",,2021,5\\'7,159lbs,88+2,88+2,88+2,92+2,93+2,93+2,93+2,92+2,93+2,93+2,93+2,91+2,84+2,84+2,84+2,91+2,64+2,61+2,61+2,61+2,64+2,59+2,47+2,47+2,47+2,59+2,84,95,70,90,86,97,93,94,87,96,91,86,91,95,95,85,68,72,59,94,48,22,94,94,75,96,33,28,26,6,11,15,14,8,€226.5M']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.textFile('data.csv',use_unicode=True)\n",
    "data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dcb7927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_line(x):\n",
    "    return x.split(',')\n",
    "\n",
    "def clubGroup(x):\n",
    "    return x[9]\n",
    "\n",
    "\n",
    "#data.map(split_line).take(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "938e31e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Club', 1),\n",
       " ('Derry City', 18),\n",
       " ('Sligo Rovers', 19),\n",
       " ('Limerick FC', 19),\n",
       " ('Grêmio', 20),\n",
       " ('Atlético Mineiro', 20),\n",
       " ('Cruzeiro', 20),\n",
       " ('Fluminense', 20),\n",
       " ('Santos', 20),\n",
       " ('Internacional', 20),\n",
       " ('América FC (Minas Gerais)', 20),\n",
       " ('Botafogo', 20),\n",
       " ('Bahia', 20),\n",
       " ('Paraná', 20),\n",
       " ('Atlético Paranaense', 20),\n",
       " ('Vitória', 20),\n",
       " ('Sport Club do Recife', 20),\n",
       " ('Chapecoense', 20),\n",
       " ('Ceará Sporting Club', 20),\n",
       " ('Tromsø IL', 20),\n",
       " ('Melbourne Victory', 21),\n",
       " ('Wellington Phoenix', 21),\n",
       " ('Dalkurd FF', 21),\n",
       " ('FK Haugesund', 22),\n",
       " ('Östersunds FK', 22),\n",
       " ('Shamrock Rovers', 22),\n",
       " ('Chicago Fire', 23),\n",
       " ('Kasimpaşa SK', 23),\n",
       " ('FC København', 23),\n",
       " ('Clube Sport Marítimo', 23),\n",
       " ('Brisbane Roar', 23),\n",
       " ('AC Ajaccio', 23),\n",
       " ('Colorado Rapids', 23),\n",
       " ('GFC Ajaccio', 23),\n",
       " ('GIF Sundsvall', 23),\n",
       " ('Dundalk', 23),\n",
       " ('Odds BK', 23),\n",
       " ('IFK Göteborg', 23),\n",
       " (\"St. Patrick's Athletic\", 23),\n",
       " ('Bray Wanderers', 23),\n",
       " ('Inter', 24),\n",
       " ('AS Saint-Étienne', 24),\n",
       " ('Atalanta', 24),\n",
       " ('Cagliari', 24),\n",
       " ('Fiorentina', 24),\n",
       " ('BSC Young Boys', 24),\n",
       " ('Viktoria Plzeň', 24),\n",
       " ('Crotone', 24),\n",
       " ('IFK Norrköping', 24),\n",
       " ('Strømsgodset IF', 24)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counting number of clubs\n",
    "\n",
    "splitRDD = data.map(split_line)\n",
    "groupByClub = splitRDD.map(lambda x:x[9])\n",
    "addOne = groupByClub.map(lambda x:(x,1))\n",
    "AggClub = addOne.reduceByKey(lambda x,y:x+y)\n",
    "ClubSorted = AggClub.sortBy(lambda x:x[1])\n",
    "ClubSorted.take(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a841056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5d5ffac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emptyRDD = sc.emptyRDD()\n",
    "emptyRDD.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "523e3052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data.csv MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df59c7dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('spark.master', 'local'),\n",
       " ('spark.app.name', 'newApp'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.driver.host', '192.168.0.108'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.app.startTime', '1646976844921'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.driver.port', '46841'),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.app.id', 'local-1646976845031')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.getConf().getAll()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610b6052",
   "metadata": {},
   "source": [
    "## RDD functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cf50b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = sc.parallelize(range(1,10),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79cc141e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9, 8, 7, 6, 5]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.takeOrdered(5, lambda x:-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33bf49ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [], [], [], [], [], [1, 2, 3, 4, 5, 6, 7, 8, 9]]\n",
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 5, 6, 7, 8, 9], [], []]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#repartition and coalesce\n",
    "numRepartitioned = num.repartition(7)\n",
    "print(numRepartitioned.glom().collect())\n",
    "numCoalesce = numRepartitioned.coalesce(3)\n",
    "print(numCoalesce.getNumPartitions())\n",
    "numCoalesce.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7efbb0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'(3) CoalescedRDD[18] at coalesce at NativeMethodAccessorImpl.java:0 []\\n |  MapPartitionsRDD[16] at coalesce at NativeMethodAccessorImpl.java:0 []\\n |  CoalescedRDD[15] at coalesce at NativeMethodAccessorImpl.java:0 []\\n |  ShuffledRDD[14] at coalesce at NativeMethodAccessorImpl.java:0 []\\n +-(1) MapPartitionsRDD[13] at coalesce at NativeMethodAccessorImpl.java:0 []\\n    |  PythonRDD[12] at RDD at PythonRDD.scala:53 []\\n    |  ParallelCollectionRDD[10] at readRDDFromFile at PythonRDD.scala:274 []'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numCoalesce.toDebugString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b4e57bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc1441cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.reduce(lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5476261e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362880"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.reduce(lambda x,y:x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c042049d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {1: 1, 2: 1, 3: 1, 4: 1, 5: 1, 6: 1, 7: 1, 8: 1, 9: 1})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ddf10b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b1fb8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.fold(3,lambda x,y:x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12c2d7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1451520"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.fold(2,lambda x,y:x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0364eff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 7, 9, 0]\n",
      "[1, 2, 3, 4, 7, 9, 0]\n"
     ]
    }
   ],
   "source": [
    "s = sc.parallelize([1,2,3,4,5,6,7,8,9,0])\n",
    "print(s.sample(False,0.8,131).collect())\n",
    "print(s.sample(False,0.8,131).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d00a5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43659e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num1 = sc.parallelize([12,28,6,4,45,69,35,75,42])\n",
    "num1.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10c5a01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 8, 1, 3, 5, 7, 9]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.subtract(num1).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5305d72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 28, 6, 4, 45, 69, 35, 75, 42]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.union(num1).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9fb6a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 6]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.intersection(num1).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3b89d6b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8a4e56ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = sc.parallelize([\"abahs\",\"jsgdj\",\"andios\",\"jdaopj\",\"baofje\"])\n",
    "\n",
    "names_grp = names.groupBy(lambda x: x[-1]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd1b4977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', <pyspark.resultiterable.ResultIterable at 0x7fcd45995520>),\n",
       " ('j', <pyspark.resultiterable.ResultIterable at 0x7fcd458ff7c0>),\n",
       " ('e', <pyspark.resultiterable.ResultIterable at 0x7fcd458ffc40>)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_grp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b747e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s ['abahs', 'andios']\n",
      "j ['jsgdj', 'jdaopj']\n",
      "e ['baofje']\n"
     ]
    }
   ],
   "source": [
    "for k,v in names_grp:\n",
    "    print(k,list(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99d5b136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.filter(lambda x : x%2==0).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "90cb08f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10, 12, 14, 16, 18]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.map(lambda x : x*2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "77237587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num.reduce(min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "27ca3115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 28, 6, 4, 45, 69, 35, 75, 42]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num1.distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cb8011",
   "metadata": {},
   "source": [
    "KEY VALUE PAIR TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2eb17d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 7), (2, 10), (3, 6)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv = sc.parallelize([(1,2),(2,3),(1,5),(3,6),(2,7)])\n",
    "kv.groupByKey().mapValues(sum).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9454c71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (2, 3), (3, 6)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv.reduceByKey(min).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b58a0e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e8bfdf",
   "metadata": {},
   "source": [
    "# DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56892155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/15 09:53:56 WARN Utils: Your hostname, shashank resolves to a loopback address: 127.0.1.1; using 192.168.0.108 instead (on interface wlp3s0)\n",
      "22/03/15 09:53:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/03/15 09:53:58 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"NewApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fac7a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"language\",\"users_count\"]\n",
    "data = [(\"Java\", 20000), (\"Python\", 100000), (\"Scala\", 3000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7589f2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#converting rdd to dataframe\n",
    "rdd = spark.sparkContext.parallelize(data)\n",
    "dfFromRdd = rdd.toDF(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "909d55c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|language|users_count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfFromRdd.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afac3c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructField,StructType,StringType,IntegerType,DateType\n",
    "from pyspark.sql.functions import lit,col, isnan, regexp_replace,avg,sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14697c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#specifying schema for dataframes\n",
    "schema = StructType([StructField(\"language\",StringType()),StructField(\"users_count\",IntegerType())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dba5064",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfSchema = spark.createDataFrame(data=data,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49d68c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|language|users_count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfSchema.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a53338f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+-------+-----+\n",
      "|language|users_count|Country|State|\n",
      "+--------+-----------+-------+-----+\n",
      "|    Java|      20000|  India|  Goa|\n",
      "|  Python|     100000|  India|  Goa|\n",
      "|   Scala|       3000|  India|  Goa|\n",
      "+--------+-----------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = dfSchema.withColumn(\"Country\",lit(\"India\")).withColumn(\"State\",lit(\"Goa\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2618d74",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Cannot modify the value of a Spark config: spark.executor.cores",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5177/741036831.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#spark.conf.set(\"spark.executor.memory\",\"4g\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.executor.cores\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/env/lib/python3.8/site-packages/pyspark/sql/conf.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;34m\"\"\"Sets the given Spark runtime configuration property.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Cannot modify the value of a Spark config: spark.executor.cores"
     ]
    }
   ],
   "source": [
    "spark.conf.set(\"spark.executor.memory\",\"4g\")\n",
    "spark.conf.set(\"spark.executor.cores\",\"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba5647bb",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o140.get.\n: java.util.NoSuchElementException: spark.executor.cores\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.noSuchElementExceptionError(QueryExecutionErrors.scala:1494)\n\tat org.apache.spark.sql.internal.SQLConf.$anonfun$getConfString$3(SQLConf.scala:4128)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.internal.SQLConf.getConfString(SQLConf.scala:4128)\n\tat org.apache.spark.sql.RuntimeConfig.get(RuntimeConfig.scala:72)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5177/2896726330.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark.executor.cores\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/env/lib/python3.8/site-packages/pyspark/sql/conf.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"key\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0m_NoValue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jconf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.8/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.8/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env/lib/python3.8/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o140.get.\n: java.util.NoSuchElementException: spark.executor.cores\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.noSuchElementExceptionError(QueryExecutionErrors.scala:1494)\n\tat org.apache.spark.sql.internal.SQLConf.$anonfun$getConfString$3(SQLConf.scala:4128)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.internal.SQLConf.getConfString(SQLConf.scala:4128)\n\tat org.apache.spark.sql.RuntimeConfig.get(RuntimeConfig.scala:72)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "spark.conf.get(\"spark.executor.cores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ea8e20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb25fde",
   "metadata": {},
   "source": [
    "## Football datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "406f2fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Column',\n",
       " 'DataFrame',\n",
       " 'DataType',\n",
       " 'PandasUDFType',\n",
       " 'PythonEvalType',\n",
       " 'SparkContext',\n",
       " 'StringType',\n",
       " 'UserDefinedFunction',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_create_column_from_literal',\n",
       " '_create_lambda',\n",
       " '_create_udf',\n",
       " '_get_get_jvm_function',\n",
       " '_get_lambda_parameters',\n",
       " '_invoke_binary_math_function',\n",
       " '_invoke_function',\n",
       " '_invoke_function_over_column',\n",
       " '_invoke_higher_order_function',\n",
       " '_options_to_str',\n",
       " '_test',\n",
       " '_to_java_column',\n",
       " '_to_seq',\n",
       " '_unresolved_named_lambda_variable',\n",
       " 'abs',\n",
       " 'acos',\n",
       " 'acosh',\n",
       " 'add_months',\n",
       " 'aggregate',\n",
       " 'approxCountDistinct',\n",
       " 'approx_count_distinct',\n",
       " 'array',\n",
       " 'array_contains',\n",
       " 'array_distinct',\n",
       " 'array_except',\n",
       " 'array_intersect',\n",
       " 'array_join',\n",
       " 'array_max',\n",
       " 'array_min',\n",
       " 'array_position',\n",
       " 'array_remove',\n",
       " 'array_repeat',\n",
       " 'array_sort',\n",
       " 'array_union',\n",
       " 'arrays_overlap',\n",
       " 'arrays_zip',\n",
       " 'asc',\n",
       " 'asc_nulls_first',\n",
       " 'asc_nulls_last',\n",
       " 'ascii',\n",
       " 'asin',\n",
       " 'asinh',\n",
       " 'assert_true',\n",
       " 'atan',\n",
       " 'atan2',\n",
       " 'atanh',\n",
       " 'avg',\n",
       " 'base64',\n",
       " 'bin',\n",
       " 'bitwiseNOT',\n",
       " 'bitwise_not',\n",
       " 'broadcast',\n",
       " 'bround',\n",
       " 'bucket',\n",
       " 'cbrt',\n",
       " 'ceil',\n",
       " 'coalesce',\n",
       " 'col',\n",
       " 'collect_list',\n",
       " 'collect_set',\n",
       " 'column',\n",
       " 'concat',\n",
       " 'concat_ws',\n",
       " 'conv',\n",
       " 'corr',\n",
       " 'cos',\n",
       " 'cosh',\n",
       " 'count',\n",
       " 'countDistinct',\n",
       " 'count_distinct',\n",
       " 'covar_pop',\n",
       " 'covar_samp',\n",
       " 'crc32',\n",
       " 'create_map',\n",
       " 'cume_dist',\n",
       " 'current_date',\n",
       " 'current_timestamp',\n",
       " 'date_add',\n",
       " 'date_format',\n",
       " 'date_sub',\n",
       " 'date_trunc',\n",
       " 'datediff',\n",
       " 'dayofmonth',\n",
       " 'dayofweek',\n",
       " 'dayofyear',\n",
       " 'days',\n",
       " 'decode',\n",
       " 'degrees',\n",
       " 'dense_rank',\n",
       " 'desc',\n",
       " 'desc_nulls_first',\n",
       " 'desc_nulls_last',\n",
       " 'element_at',\n",
       " 'encode',\n",
       " 'exists',\n",
       " 'exp',\n",
       " 'explode',\n",
       " 'explode_outer',\n",
       " 'expm1',\n",
       " 'expr',\n",
       " 'factorial',\n",
       " 'filter',\n",
       " 'first',\n",
       " 'flatten',\n",
       " 'floor',\n",
       " 'forall',\n",
       " 'format_number',\n",
       " 'format_string',\n",
       " 'from_csv',\n",
       " 'from_json',\n",
       " 'from_unixtime',\n",
       " 'from_utc_timestamp',\n",
       " 'functools',\n",
       " 'get_json_object',\n",
       " 'greatest',\n",
       " 'grouping',\n",
       " 'grouping_id',\n",
       " 'hash',\n",
       " 'hex',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'hypot',\n",
       " 'initcap',\n",
       " 'input_file_name',\n",
       " 'instr',\n",
       " 'isnan',\n",
       " 'isnull',\n",
       " 'json_tuple',\n",
       " 'kurtosis',\n",
       " 'lag',\n",
       " 'last',\n",
       " 'last_day',\n",
       " 'lead',\n",
       " 'least',\n",
       " 'length',\n",
       " 'levenshtein',\n",
       " 'lit',\n",
       " 'locate',\n",
       " 'log',\n",
       " 'log10',\n",
       " 'log1p',\n",
       " 'log2',\n",
       " 'lower',\n",
       " 'lpad',\n",
       " 'ltrim',\n",
       " 'map_concat',\n",
       " 'map_entries',\n",
       " 'map_filter',\n",
       " 'map_from_arrays',\n",
       " 'map_from_entries',\n",
       " 'map_keys',\n",
       " 'map_values',\n",
       " 'map_zip_with',\n",
       " 'max',\n",
       " 'md5',\n",
       " 'mean',\n",
       " 'min',\n",
       " 'minute',\n",
       " 'monotonically_increasing_id',\n",
       " 'month',\n",
       " 'months',\n",
       " 'months_between',\n",
       " 'nanvl',\n",
       " 'next_day',\n",
       " 'nth_value',\n",
       " 'ntile',\n",
       " 'overlay',\n",
       " 'pandas_udf',\n",
       " 'percent_rank',\n",
       " 'percentile_approx',\n",
       " 'posexplode',\n",
       " 'posexplode_outer',\n",
       " 'pow',\n",
       " 'product',\n",
       " 'quarter',\n",
       " 'radians',\n",
       " 'raise_error',\n",
       " 'rand',\n",
       " 'randn',\n",
       " 'rank',\n",
       " 'regexp_extract',\n",
       " 'regexp_replace',\n",
       " 'repeat',\n",
       " 'reverse',\n",
       " 'rint',\n",
       " 'round',\n",
       " 'row_number',\n",
       " 'rpad',\n",
       " 'rtrim',\n",
       " 'schema_of_csv',\n",
       " 'schema_of_json',\n",
       " 'second',\n",
       " 'sentences',\n",
       " 'sequence',\n",
       " 'session_window',\n",
       " 'sha1',\n",
       " 'sha2',\n",
       " 'shiftLeft',\n",
       " 'shiftRight',\n",
       " 'shiftRightUnsigned',\n",
       " 'shiftleft',\n",
       " 'shiftright',\n",
       " 'shiftrightunsigned',\n",
       " 'shuffle',\n",
       " 'signum',\n",
       " 'sin',\n",
       " 'since',\n",
       " 'sinh',\n",
       " 'size',\n",
       " 'skewness',\n",
       " 'slice',\n",
       " 'sort_array',\n",
       " 'soundex',\n",
       " 'spark_partition_id',\n",
       " 'split',\n",
       " 'sqrt',\n",
       " 'stddev',\n",
       " 'stddev_pop',\n",
       " 'stddev_samp',\n",
       " 'struct',\n",
       " 'substring',\n",
       " 'substring_index',\n",
       " 'sum',\n",
       " 'sumDistinct',\n",
       " 'sum_distinct',\n",
       " 'sys',\n",
       " 'tan',\n",
       " 'tanh',\n",
       " 'timestamp_seconds',\n",
       " 'toDegrees',\n",
       " 'toRadians',\n",
       " 'to_csv',\n",
       " 'to_date',\n",
       " 'to_json',\n",
       " 'to_str',\n",
       " 'to_timestamp',\n",
       " 'to_utc_timestamp',\n",
       " 'transform',\n",
       " 'transform_keys',\n",
       " 'transform_values',\n",
       " 'translate',\n",
       " 'trim',\n",
       " 'trunc',\n",
       " 'udf',\n",
       " 'unbase64',\n",
       " 'unhex',\n",
       " 'unix_timestamp',\n",
       " 'upper',\n",
       " 'var_pop',\n",
       " 'var_samp',\n",
       " 'variance',\n",
       " 'warnings',\n",
       " 'weekofyear',\n",
       " 'when',\n",
       " 'window',\n",
       " 'xxhash64',\n",
       " 'year',\n",
       " 'years',\n",
       " 'zip_with']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "dir(pyspark.sql.functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "85384292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(ID=158023, Name='L. Messi', Age=31, Nationality='Argentina', Overall=94, Club='FC Barcelona', Value='€110.5M', Joined='Jul 1, 2004')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = ['ID','Name','Age','Nationality','Overall','Club','Value','Joined']\n",
    "df = spark.read.csv('data.csv',header=True,inferSchema=True).select(col)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71e870d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faf0fcc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 11:>                                                         (0 + 3) / 3]\r",
      "\r",
      "[Stage 11:======================================>                   (2 + 1) / 3]\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.repartition(10)\n",
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfabc684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18207"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8fbfd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------+---+------------------+-------+--------------------+------+------------+\n",
      "|ID    |Name         |Age|Nationality       |Overall|Club                |Value |Joined      |\n",
      "+------+-------------+---+------------------+-------+--------------------+------+------------+\n",
      "|205965|S. Ristovski |26 |FYR Macedonia     |76     |Sporting CP         |€7.5M |Aug 8, 2017 |\n",
      "|227557|M. Cassierra |21 |Colombia          |70     |FC Groningen        |€2.7M |null        |\n",
      "|236639|Xeka         |23 |Portugal          |73     |LOSC Lille          |€4.7M |Jul 1, 2017 |\n",
      "|131444|R. Würtz     |34 |Denmark           |68     |Aalborg BK          |€425K |Jul 9, 2009 |\n",
      "|190467|D. de Buen   |26 |Mexico            |70     |Santos Laguna       |€1.8M |Jan 1, 2016 |\n",
      "|187517|V. Vasin     |29 |Russia            |77     |PFC CSKA Moscow     |€7M   |Jan 1, 2011 |\n",
      "|229857|S. Sensi     |22 |Italy             |72     |Sassuolo            |€3.5M |Jan 13, 2016|\n",
      "|226436|H. ter Avest |21 |Netherlands       |69     |Udinese             |€1.3M |Jul 5, 2018 |\n",
      "|198964|Tyronne      |27 |Spain             |68     |CD Tenerife         |€950K |Jul 15, 2017|\n",
      "|212188|T. Werner    |22 |Germany           |83     |RB Leipzig          |€34.5M|Jul 1, 2016 |\n",
      "|6826  |G. Barry     |37 |England           |72     |West Bromwich Albion|€425K |Aug 15, 2017|\n",
      "|212300|J. O'Connell |24 |England           |73     |Sheffield United    |€4.8M |Jul 8, 2016 |\n",
      "|226370|André Horta  |21 |Portugal          |74     |Los Angeles FC      |€8M   |Jul 10, 2018|\n",
      "|221675|C. Mosquera  |27 |Colombia          |70     |Patriotas Boyacá FC |€1.9M |Jan 20, 2017|\n",
      "|204830|Vadillo      |23 |Spain             |71     |Granada CF          |€3.2M |Jul 1, 2018 |\n",
      "|193421|Javi Lara    |32 |Spain             |70     |Córdoba CF          |€1.3M |Jan 10, 2017|\n",
      "|244264|A. Gojak     |21 |Bosnia Herzegovina|69     |Dinamo Zagreb       |€1.6M |Feb 13, 2015|\n",
      "|239433|N. Maksimović|23 |Serbia            |74     |Getafe CF           |€8M   |Jul 16, 2018|\n",
      "|184926|Fabiano      |30 |Brazil            |73     |FC Porto            |€3M   |Jul 1, 2012 |\n",
      "|213642|J. Wilson    |22 |England           |67     |Aberdeen            |€1.1M |null        |\n",
      "+------+-------------+---+------------------+-------+--------------------+------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5c1de1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+---+-----------+-------+-------------------+-----------+------------+\n",
      "|    ID|             Name|Age|Nationality|Overall|               Club|      Value|      Joined|\n",
      "+------+-----------------+---+-----------+-------+-------------------+-----------+------------+\n",
      "|158023|         L. Messi| 31|  Argentina|     94|       FC Barcelona|11050000000| Jul 1, 2004|\n",
      "| 20801|Cristiano Ronaldo| 33|   Portugal|     94|           Juventus|  770000000|Jul 10, 2018|\n",
      "|190871|        Neymar Jr| 26|     Brazil|     92|Paris Saint-Germain|11850000000| Aug 3, 2017|\n",
      "|193080|           De Gea| 27|      Spain|     91|  Manchester United|  720000000| Jul 1, 2011|\n",
      "|192985|     K. De Bruyne| 27|    Belgium|     91|    Manchester City| 1020000000|Aug 30, 2015|\n",
      "+------+-----------------+---+-----------+-------+-------------------+-----------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#changing the datatypes of value column\n",
    "df.dtypes\n",
    "df = df.withColumn('Value', regexp_replace('Value','[€,.]',''))\n",
    "df = df.withColumn('Value', regexp_replace('Value','[M]','0000000'))\n",
    "df = df.withColumn('Value', regexp_replace('Value','[K]','000'))\n",
    "df = df.withColumn('Value',df.Value.cast('long'))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f6a71aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Nationality: string (nullable = true)\n",
      " |-- Overall: integer (nullable = true)\n",
      " |-- Club: string (nullable = true)\n",
      " |-- Value: long (nullable = true)\n",
      " |-- Joined: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f809d1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+--------------------------------------------+\n",
      "|count(CASE WHEN (Club IS NULL) THEN true END)|count(CASE WHEN (Age IS NULL) THEN true END)|\n",
      "+---------------------------------------------+--------------------------------------------+\n",
      "|                                          241|                                           0|\n",
      "+---------------------------------------------+--------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#checking number of null values\n",
    "\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "df.select([count(when(col('Club').isNull(),True)),count(when(col('Age').isNull(),True))]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1038d197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+\n",
      "|count(CASE WHEN (Club IS NULL) THEN true END)|\n",
      "+---------------------------------------------+\n",
      "|                                          241|\n",
      "+---------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(count(when(col('Club').isNull(),True))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c8ebb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+---+------------+-------+----+-----+------+\n",
      "|    ID|        Name|Age| Nationality|Overall|Club|Value|Joined|\n",
      "+------+------------+---+------------+-------+----+-----+------+\n",
      "|174381|  C. Riveros| 35|    Paraguay|     76|null|    0|  null|\n",
      "|165429|   C. Keşerü| 31|     Romania|     73|null|    0|  null|\n",
      "|203594|   H. Kekana| 33|South Africa|     69|null|    0|  null|\n",
      "|214692|    C. Cueva| 26|        Peru|     75|null|    0|  null|\n",
      "|225900|J. Sambenito| 26|    Paraguay|     71|null|    0|  null|\n",
      "+------+------------+---+------------+-------+----+-----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(col('Club').isNull()).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c84f5218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18207"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de24714c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "241"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "18207-17966"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a82db356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping rows with na value\n",
    "df_drop = df.na.drop(how='any',subset=['Club'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "301f78c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+---+------------+-------+------+-----+------+\n",
      "|    ID|          Name|Age| Nationality|Overall|  Club|Value|Joined|\n",
      "+------+--------------+---+------------+-------+------+-----+------+\n",
      "|174381|    C. Riveros| 35|    Paraguay|     76|Fc_Goa|    0|  null|\n",
      "|165429|     C. Keşerü| 31|     Romania|     73|Fc_Goa|    0|  null|\n",
      "|203594|     H. Kekana| 33|South Africa|     69|Fc_Goa|    0|  null|\n",
      "|214692|      C. Cueva| 26|        Peru|     75|Fc_Goa|    0|  null|\n",
      "|225900|  J. Sambenito| 26|    Paraguay|     71|Fc_Goa|    0|  null|\n",
      "|169423|     S. Ekramy| 34|       Egypt|     69|Fc_Goa|    0|  null|\n",
      "|153160|     R. Raldes| 37|     Bolivia|     70|Fc_Goa|    0|  null|\n",
      "|204341|     Luís Neto| 30|    Portugal|     77|Fc_Goa|    0|  null|\n",
      "|216335|  Y. Gazinskiy| 28|      Russia|     75|Fc_Goa|    0|  null|\n",
      "|241234|   P. Mahlambi| 20|South Africa|     70|Fc_Goa|    0|  null|\n",
      "|224909|    P. Aguedar| 30|    Paraguay|     74|Fc_Goa|    0|  null|\n",
      "|201707|      A. Fiola| 28|     Hungary|     72|Fc_Goa|    0|  null|\n",
      "|193359|       R. Romo| 28|   Venezuela|     69|Fc_Goa|    0|  null|\n",
      "|223152|   S. Vilakazi| 28|South Africa|     74|Fc_Goa|    0|  null|\n",
      "|222402|     J. Gulley| 25| New Zealand|     61|Fc_Goa|    0|  null|\n",
      "|169424|I. Bandalovski| 31|    Bulgaria|     67|Fc_Goa|    0|  null|\n",
      "|208543|   C. Howieson| 23| New Zealand|     63|Fc_Goa|    0|  null|\n",
      "|246406|    X. Arreaga| 23|     Ecuador|     66|Fc_Goa|    0|  null|\n",
      "|228199|    H. Narzary| 24|       India|     60|Fc_Goa|    0|  null|\n",
      "|236582|     M. Raynov| 26|    Bulgaria|     62|Fc_Goa|    0|  null|\n",
      "+------+--------------+---+------------+-------+------+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fill = df.na.fill(\"Fc_Goa\",subset=['Club'])  #filling the na values\n",
    "df_fill.filter(df_fill.Club==\"Fc_Goa\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d620bdba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18207"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e3dae998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---------+---+-----------+-------+------------+----------+--------------+\n",
      "|    ID|     Name|Age|Nationality|Overall|        Club|     Value|Preferred foot|\n",
      "+------+---------+---+-----------+-------+------------+----------+--------------+\n",
      "|230658|   Arthur| 21|     Brazil|     82|FC Barcelona|3250000000|         Right|\n",
      "|241810|    Chumi| 19|      Spain|     65|FC Barcelona|  10000000|         Right|\n",
      "|237156| M. Wagué| 19|    Senegal|     69|FC Barcelona| 160000000|         Right|\n",
      "|152729|    Piqué| 31|      Spain|     87|FC Barcelona| 340000000|         Right|\n",
      "|205600|S. Umtiti| 24|     France|     87|FC Barcelona| 570000000|          Left|\n",
      "+------+---------+---+-----------+-------+------------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.Club == 'FC Barcelona').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c3c9686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+--------------------+---+\n",
      "| ID|Condition|                Club|Age|\n",
      "+---+---------+--------------------+---+\n",
      "| 16|     more|           KAS Eupen| 37|\n",
      "| 41|     more|         Vissel Kobe| 34|\n",
      "| 80|     more|Medipol Başakşehi...| 37|\n",
      "|164|     more|              Padova| 37|\n",
      "|657|     more|        Notts County| 35|\n",
      "+---+---------+--------------------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('ID',when(col('Age')<25,'less').otherwise('more').alias('Condition'),'Club','Age').orderBy('ID').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8478c79b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|Preferred foot|\n",
      "+--------------+\n",
      "|             R|\n",
      "|             R|\n",
      "|             R|\n",
      "|             R|\n",
      "+--------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Preferred foot\").replace('Left','L').replace('Right','R').show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a564284",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16654"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.na.drop().count()\n",
    "#df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7f94517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18207"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('Value').na.drop().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "235a0db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18207"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97acd1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---+-----------+-------+------------+-----------+-----------+\n",
      "|    ID|    Name|Age|Nationality|Overall|        Club|      Value|     Joined|\n",
      "+------+--------+---+-----------+-------+------------+-----------+-----------+\n",
      "|158023|L. Messi| 31|  Argentina|     94|FC Barcelona|11050000000|Jul 1, 2004|\n",
      "+------+--------+---+-----------+-------+------------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\"Nationality == 'Argentina' and Club=='FC Barcelona'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "957db44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------+\n",
      "|       Club|          Overall|\n",
      "+-----------+-----------------+\n",
      "|   Juventus|            82.28|\n",
      "|     Napoli|             80.0|\n",
      "|      Inter|            79.75|\n",
      "|Real Madrid|78.24242424242425|\n",
      "|      Milan|78.07407407407408|\n",
      "+-----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Club\").mean().select('Club',col('avg(Overall)').alias('Overall')).sort('Overall',ascending=False).show(5) #.sort('avg(Overall)',ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8e65852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-----------------+\n",
      "|Age|               Value|       Avg-Rating|\n",
      "+---+--------------------+-----------------+\n",
      "| 45|            160000.0|             71.0|\n",
      "| 31|1.7114712871287128E8|69.85007072135785|\n",
      "| 30|1.9675604689203927E8|69.69574700109051|\n",
      "| 33| 9.711901960784313E7|69.55882352941177|\n",
      "| 34| 8.979554455445544E7|69.53960396039604|\n",
      "| 32|1.2563178571428572E8|69.52961672473867|\n",
      "| 29|1.6259561522419187E8| 69.2460896767466|\n",
      "| 28|1.5432655767484105E8|69.21344232515895|\n",
      "| 27|1.8431769363166952E8|68.94922547332186|\n",
      "| 37| 2.776798780487805E7| 68.9390243902439|\n",
      "+---+--------------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#df.groupBy('Club').sum('Value').alias('Total_spent').sort('sum(Value)',ascending=False).show(10)\n",
    "df.groupBy('Age').agg(avg('Value').alias('Value'),avg('Overall').alias('Avg-Rating')).sort('Avg-Rating',ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2f7ae859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "652"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/15 16:01:34 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 2879706 ms exceeds timeout 120000 ms\n",
      "22/03/15 16:01:34 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "df.select('Club').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "cc9e72bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumnRenamed('Preferred foot','Preferred_foot')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e576c474",
   "metadata": {},
   "source": [
    "## aggregate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f4e7058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f216c03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "club_list_duplicates = df.select(f.collect_list(\"Club\")).collect()[0][0]\n",
    "club_list_distinct = df.select(f.collect_set(\"Club\")).collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "ff39db81",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Column', 'DataFrame', 'DataType', 'PandasUDFType', 'PythonEvalType', 'SparkContext', 'StringType', 'UserDefinedFunction', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_create_column_from_literal', '_create_lambda', '_create_udf', '_get_get_jvm_function', '_get_lambda_parameters', '_invoke_binary_math_function', '_invoke_function', '_invoke_function_over_column', '_invoke_higher_order_function', '_options_to_str', '_test', '_to_java_column', '_to_seq', '_unresolved_named_lambda_variable', 'abs', 'acos', 'acosh', 'add_months', 'aggregate', 'approxCountDistinct', 'approx_count_distinct', 'array', 'array_contains', 'array_distinct', 'array_except', 'array_intersect', 'array_join', 'array_max', 'array_min', 'array_position', 'array_remove', 'array_repeat', 'array_sort', 'array_union', 'arrays_overlap', 'arrays_zip', 'asc', 'asc_nulls_first', 'asc_nulls_last', 'ascii', 'asin', 'asinh', 'assert_true', 'atan', 'atan2', 'atanh', 'avg', 'base64', 'bin', 'bitwiseNOT', 'bitwise_not', 'broadcast', 'bround', 'bucket', 'cbrt', 'ceil', 'coalesce', 'col', 'collect_list', 'collect_set', 'column', 'concat', 'concat_ws', 'conv', 'corr', 'cos', 'cosh', 'count', 'countDistinct', 'count_distinct', 'covar_pop', 'covar_samp', 'crc32', 'create_map', 'cume_dist', 'current_date', 'current_timestamp', 'date_add', 'date_format', 'date_sub', 'date_trunc', 'datediff', 'dayofmonth', 'dayofweek', 'dayofyear', 'days', 'decode', 'degrees', 'dense_rank', 'desc', 'desc_nulls_first', 'desc_nulls_last', 'element_at', 'encode', 'exists', 'exp', 'explode', 'explode_outer', 'expm1', 'expr', 'factorial', 'filter', 'first', 'flatten', 'floor', 'forall', 'format_number', 'format_string', 'from_csv', 'from_json', 'from_unixtime', 'from_utc_timestamp', 'functools', 'get_json_object', 'greatest', 'grouping', 'grouping_id', 'hash', 'hex', 'hour', 'hours', 'hypot', 'initcap', 'input_file_name', 'instr', 'isnan', 'isnull', 'json_tuple', 'kurtosis', 'lag', 'last', 'last_day', 'lead', 'least', 'length', 'levenshtein', 'lit', 'locate', 'log', 'log10', 'log1p', 'log2', 'lower', 'lpad', 'ltrim', 'map_concat', 'map_entries', 'map_filter', 'map_from_arrays', 'map_from_entries', 'map_keys', 'map_values', 'map_zip_with', 'max', 'md5', 'mean', 'min', 'minute', 'monotonically_increasing_id', 'month', 'months', 'months_between', 'nanvl', 'next_day', 'nth_value', 'ntile', 'overlay', 'pandas_udf', 'percent_rank', 'percentile_approx', 'posexplode', 'posexplode_outer', 'pow', 'product', 'quarter', 'radians', 'raise_error', 'rand', 'randn', 'rank', 'regexp_extract', 'regexp_replace', 'repeat', 'reverse', 'rint', 'round', 'row_number', 'rpad', 'rtrim', 'schema_of_csv', 'schema_of_json', 'second', 'sentences', 'sequence', 'session_window', 'sha1', 'sha2', 'shiftLeft', 'shiftRight', 'shiftRightUnsigned', 'shiftleft', 'shiftright', 'shiftrightunsigned', 'shuffle', 'signum', 'sin', 'since', 'sinh', 'size', 'skewness', 'slice', 'sort_array', 'soundex', 'spark_partition_id', 'split', 'sqrt', 'stddev', 'stddev_pop', 'stddev_samp', 'struct', 'substring', 'substring_index', 'sum', 'sumDistinct', 'sum_distinct', 'sys', 'tan', 'tanh', 'timestamp_seconds', 'toDegrees', 'toRadians', 'to_csv', 'to_date', 'to_json', 'to_str', 'to_timestamp', 'to_utc_timestamp', 'transform', 'transform_keys', 'transform_values', 'translate', 'trim', 'trunc', 'udf', 'unbase64', 'unhex', 'unix_timestamp', 'upper', 'var_pop', 'var_samp', 'variance', 'warnings', 'weekofyear', 'when', 'window', 'xxhash64', 'year', 'years', 'zip_with']\n"
     ]
    }
   ],
   "source": [
    "print(dir(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "292d9486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133932346.89954413"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(f.avg(\"Value\")).collect()[0][0]   #max,min,mean,sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e0f4ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|   first(Name)|\n",
      "+--------------+\n",
      "|P. Abrahamsson|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(f.first(\"Name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1f9cbe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.select('Name',f.expr(\"Name || '-' || Age\").alias(\"Name-Age\"))              #expr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b37e24e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----------+\n",
      "|      Name|     Name-Age|      Prof|\n",
      "+----------+-------------+----------+\n",
      "|Ibai Gómez|Ibai Gómez-28|Footballer|\n",
      "| B. Başdaş| B. Başdaş-28|Footballer|\n",
      "+----------+-------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_df.select('Name','Name-Age',f.lit(\"Footballer\").alias(\"Prof\")).show(2)             #lit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c493bae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- year: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      "\n",
      "+---+--------+----+-----+---+\n",
      "|id |date    |year|month|day|\n",
      "+---+--------+----+-----+---+\n",
      "|1  |20200828|2020|08   |28 |\n",
      "|2  |20180525|2018|05   |25 |\n",
      "+---+--------+----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(1,\"20200828\"),(2,\"20180525\")]\n",
    "columns=[\"id\",\"date\"]\n",
    "dataF=spark.createDataFrame(data,columns)\n",
    "dataF = dataF.withColumn('year', f.substring('date', 1,4)).withColumn('month', f.substring('date', 5,2)).withColumn('day', f.substring('date', 7,2))\n",
    "dataF.printSchema()\n",
    "dataF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e120ddf9",
   "metadata": {},
   "source": [
    "## sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7514ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+---+-------------+-------+--------------------+----------+------------+\n",
      "|    ID|        Name|Age|  Nationality|Overall|                Club|     Value|      Joined|\n",
      "+------+------------+---+-------------+-------+--------------------+----------+------------+\n",
      "|205965|S. Ristovski| 26|FYR Macedonia|     76|         Sporting CP| 750000000| Aug 8, 2017|\n",
      "|212188|   T. Werner| 22|      Germany|     83|          RB Leipzig|3450000000| Jul 1, 2016|\n",
      "|226370| André Horta| 21|     Portugal|     74|      Los Angeles FC|  80000000|Jul 10, 2018|\n",
      "|213777|   I. Fossum| 21|       Norway|     73|         Hannover 96| 550000000| Jan 1, 2016|\n",
      "|149258|   A. Cordaz| 35|        Italy|     72|             Crotone|    725000| Jul 9, 2015|\n",
      "|225100|    J. Gomez| 21|      England|     78|           Liverpool|1450000000|Jun 20, 2015|\n",
      "|230758|    M. Pučko| 24|     Slovenia|     67|       Korona Kielce|  10000000|Aug 14, 2018|\n",
      "|216283|      Danilo| 26|       Brazil|     72|     VfL Bochum 1848|  30000000| Jul 1, 2017|\n",
      "|169498|   J. Garner| 30|      England|     71|      Wigan Athletic| 230000000| Aug 9, 2018|\n",
      "|166664|    Molinero| 32|        Spain|     73|Real Sporting de ...| 220000000|Jul 12, 2018|\n",
      "+------+------------+---+-------------+-------+--------------------+----------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sample(0.1).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5623f32f",
   "metadata": {},
   "source": [
    "## Saving Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "418e5ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('./just_parquet',mode='overwrite',partitionBy=\"Club\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dadf6499",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.csv('./just_csv',mode='overwrite',sep=',',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d32695cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(1)\n",
    "df.select('Name').write.mode('overwrite').text('./just_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c762c3e",
   "metadata": {},
   "source": [
    "## temporary views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca3cd784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/15 10:04:15 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView('stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b26559e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+---+-------------+-------+---------------+----------+------------+\n",
      "|    ID|        Name|Age|  Nationality|Overall|           Club|     Value|      Joined|\n",
      "+------+------------+---+-------------+-------+---------------+----------+------------+\n",
      "|205965|S. Ristovski| 26|FYR Macedonia|     76|    Sporting CP| 750000000| Aug 8, 2017|\n",
      "|227557|M. Cassierra| 21|     Colombia|     70|   FC Groningen| 270000000|        null|\n",
      "|236639|        Xeka| 23|     Portugal|     73|     LOSC Lille| 470000000| Jul 1, 2017|\n",
      "|131444|    R. Würtz| 34|      Denmark|     68|     Aalborg BK|    425000| Jul 9, 2009|\n",
      "|190467|  D. de Buen| 26|       Mexico|     70|  Santos Laguna| 180000000| Jan 1, 2016|\n",
      "|187517|    V. Vasin| 29|       Russia|     77|PFC CSKA Moscow|  70000000| Jan 1, 2011|\n",
      "|229857|    S. Sensi| 22|        Italy|     72|       Sassuolo| 350000000|Jan 13, 2016|\n",
      "|226436|H. ter Avest| 21|  Netherlands|     69|        Udinese| 130000000| Jul 5, 2018|\n",
      "|198964|     Tyronne| 27|        Spain|     68|    CD Tenerife|    950000|Jul 15, 2017|\n",
      "|212188|   T. Werner| 22|      Germany|     83|     RB Leipzig|3450000000| Jul 1, 2016|\n",
      "+------+------------+---+-------------+-------+---------------+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from stats limit 10').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17191b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+---+-----------+-------+-----+--------------+----+\n",
      "|    ID|        Name|Age|Nationality|Overall|Value|Preferred_foot|Club|\n",
      "+------+------------+---+-----------+-------+-----+--------------+----+\n",
      "|207439|  L. Paredes| 24|  Argentina|     80|    0|         Right|null|\n",
      "|156713|A. Granqvist| 33|     Sweden|     80|    0|         Right|null|\n",
      "|229909|    A. Lunev| 26|     Russia|     79|    0|         Right|null|\n",
      "|187347|I. Smolnikov| 29|     Russia|     79|    0|         Right|null|\n",
      "|187607|   A. Dzyuba| 29|     Russia|     78|    0|         Right|null|\n",
      "|204341|   Luís Neto| 30|   Portugal|     77|    0|         Right|null|\n",
      "|223058|  D. Kuzyaev| 25|     Russia|     77|    0|         Right|null|\n",
      "|183389|      G. Sio| 29|Ivory Coast|     77|    0|          Left|null|\n",
      "|156092|   J. Villar| 41|   Paraguay|     77|    0|         Right|null|\n",
      "|174381|  C. Riveros| 35|   Paraguay|     76|    0|         Right|null|\n",
      "+------+------------+---+-----------+-------+-----+--------------+----+\n",
      "\n",
      "+-----------------+\n",
      "|              _c0|\n",
      "+-----------------+\n",
      "|         L. Messi|\n",
      "|Cristiano Ronaldo|\n",
      "|        Neymar Jr|\n",
      "|           De Gea|\n",
      "|     K. De Bruyne|\n",
      "|        E. Hazard|\n",
      "|        L. Modrić|\n",
      "|        L. Suárez|\n",
      "|     Sergio Ramos|\n",
      "|         J. Oblak|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from parquet.`./just_parquet` limit 10').show(10)\n",
    "spark.sql('select * from csv.`./just_text` limit 10').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d0c1c637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+---+-------------+-------+------------+---------+-----------+\n",
      "|    ID|        Name|Age|  Nationality|Overall|        Club|    Value|     Joined|\n",
      "+------+------------+---+-------------+-------+------------+---------+-----------+\n",
      "|205965|S. Ristovski| 26|FYR Macedonia|     76| Sporting CP|750000000|Aug 8, 2017|\n",
      "|227557|M. Cassierra| 21|     Colombia|     70|FC Groningen|270000000|       null|\n",
      "+------+------------+---+-------------+-------+------------+---------+-----------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+------+-------------+---+-----------------+-------+--------------------+------+------------+\n",
      "|    ID|         Name|Age|      Nationality|Overall|                Club| Value|      Joined|\n",
      "+------+-------------+---+-----------------+-------+--------------------+------+------------+\n",
      "|140029|     O. Pérez| 45|           Mexico|     71|             Pachuca|160000| Jun 1, 1991|\n",
      "| 51963|    T. Warner| 44|Trinidad & Tobago|     53|  Accrington Stanley|     0| Aug 3, 2018|\n",
      "| 53748|K. Pilkington| 44|          England|     48|    Cambridge United|     0|Aug 17, 2018|\n",
      "|140183|  S. Narazaki| 42|            Japan|     65|      Nagoya Grampus| 40000| Jan 1, 1999|\n",
      "|156092|    J. Villar| 41|         Paraguay|     77|                null|     0|        null|\n",
      "|  3665|     B. Nivet| 41|           France|     71|        ESTAC Troyes|     0| Jul 1, 2012|\n",
      "| 18745|     M. Tyler| 41|          England|     59| Peterborough United| 10000| Mar 8, 2016|\n",
      "|208927| H. Sulaimani| 41|     Saudi Arabia|     63|           Ohod Club|     0|Jun 11, 2018|\n",
      "|142998|     C. Muñoz| 41|        Argentina|     68|CD Universidad de...| 60000| Jan 1, 2013|\n",
      "| 29552|  S. Nakamura| 40|            Japan|     72|        Júbilo Iwata|     0|Jan 10, 2017|\n",
      "+------+-------------+---+-----------------+-------+--------------------+------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView('new_view')\n",
    "reloaded_table = spark.table('new_view')\n",
    "reloaded_table.show(2)\n",
    "reloaded_table.sort('Age',ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e155b363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='new_view', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='stats', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9e4dbec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('drop table modified_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d87a5fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#persistent table\n",
    "\n",
    "df.write.option('path','./tables').saveAsTable('modified_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ab320651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---+-----------+-------+-------------------+---------+--------------+\n",
      "|    ID|       Name|Age|Nationality|Overall|               Club|    Value|Preferred_foot|\n",
      "+------+-----------+---+-----------+-------+-------------------+---------+--------------+\n",
      "|192255|P. Maiorino| 29|      Italy|     62|            Livorno|   300000|         Right|\n",
      "|210556| Lucas João| 24|   Portugal|     69|Sheffield Wednesday|140000000|         Right|\n",
      "|208158| F. Andrada| 24|  Argentina|     69|  Unión de Santa Fe|150000000|         Right|\n",
      "|238468|    C. Mesa| 20|   Colombia|     50|    América de Cali|    60000|         Right|\n",
      "|234178|   L. Abram| 22|       Peru|     70|    Vélez Sarsfield|240000000|          Left|\n",
      "+------+-----------+---+-----------+-------+-------------------+---------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from parquet.`./tables`').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b152ec88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+---+-----------+-------+----+-----+--------------+\n",
      "| ID|Name|Age|Nationality|Overall|Club|Value|Preferred_foot|\n",
      "+---+----+---+-----------+-------+----+-----+--------------+\n",
      "+---+----+---+-----------+-------+----+-----+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/11 13:44:31 WARN HadoopFSUtils: The directory file:/home/shashank/Practice/spark-warehouse/tables was not found. Was it deleted very recently?\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select * from modified_table limit 10').show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890c492e",
   "metadata": {},
   "source": [
    "# JOINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb140154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- emp_id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- superior_emp_id: long (nullable = true)\n",
      " |-- year_joined: string (nullable = true)\n",
      " |-- emp_dept_id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      "\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |\n",
      "|6     |Brown   |2              |2010       |50         |      |-1    |\n",
      "+------+--------+---------------+-----------+-----------+------+------+\n",
      "\n",
      "root\n",
      " |-- dept_name: string (nullable = true)\n",
      " |-- dept_id: long (nullable = true)\n",
      "\n",
      "+---------+-------+\n",
      "|dept_name|dept_id|\n",
      "+---------+-------+\n",
      "|Finance  |10     |\n",
      "|Marketing|20     |\n",
      "|Sales    |30     |\n",
      "|IT       |40     |\n",
      "+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "emp = [(1,\"Smith\",-1,\"2018\",\"10\",\"M\",3000),\n",
    "    (2,\"Rose\",1,\"2010\",\"20\",\"M\",4000),\n",
    "    (3,\"Williams\",1,\"2010\",\"10\",\"M\",1000),\n",
    "    (4,\"Jones\",2,\"2005\",\"10\",\"F\",2000),\n",
    "    (5,\"Brown\",2,\"2010\",\"40\",\"\",-1),\n",
    "      (6,\"Brown\",2,\"2010\",\"50\",\"\",-1)\n",
    "  ]\n",
    "empColumns = [\"emp_id\",\"name\",\"superior_emp_id\",\"year_joined\",\n",
    "       \"emp_dept_id\",\"gender\",\"salary\"]\n",
    "\n",
    "empDF = spark.createDataFrame(data=emp, schema = empColumns)\n",
    "empDF.printSchema()\n",
    "empDF.show(truncate=False)\n",
    "\n",
    "dept = [(\"Finance\",10),\n",
    "    (\"Marketing\",20),\n",
    "    (\"Sales\",30),\n",
    "    (\"IT\",40)\n",
    "  ]\n",
    "\n",
    "deptColumns = [\"dept_name\",\"dept_id\"]\n",
    "deptDF = spark.createDataFrame(data=dept, schema = deptColumns)\n",
    "deptDF.printSchema()\n",
    "deptDF.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "53bdc997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------+\n",
      "|emp_id|    name|dept_name|\n",
      "+------+--------+---------+\n",
      "|     1|   Smith|  Finance|\n",
      "|     3|Williams|  Finance|\n",
      "|     4|   Jones|  Finance|\n",
      "|     2|    Rose|Marketing|\n",
      "|     5|   Brown|       IT|\n",
      "+------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "empDF.join(deptDF,empDF.emp_dept_id ==  deptDF.dept_id,\"inner\").select('emp_id','name','dept_name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcb3a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#joins \"inner\",\"left\",\"right\",\"full\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "101b05c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "empDF.createOrReplaceTempView(\"EMP\")\n",
    "deptDF.createOrReplaceTempView(\"DEPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e305d3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|emp_id|name    |superior_emp_id|year_joined|emp_dept_id|gender|salary|dept_name|dept_id|\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "|1     |Smith   |-1             |2018       |10         |M     |3000  |Finance  |10     |\n",
      "|3     |Williams|1              |2010       |10         |M     |1000  |Finance  |10     |\n",
      "|4     |Jones   |2              |2005       |10         |F     |2000  |Finance  |10     |\n",
      "|2     |Rose    |1              |2010       |20         |M     |4000  |Marketing|20     |\n",
      "|5     |Brown   |2              |2010       |40         |      |-1    |IT       |40     |\n",
      "+------+--------+---------------+-----------+-----------+------+------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinDF2 = spark.sql(\"select * from EMP e INNER JOIN DEPT d ON e.emp_dept_id == d.dept_id\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3c8a6c",
   "metadata": {},
   "source": [
    "## Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "da753159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|       Robert|     Sales|   CA| 81000| 30|23000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|        Maria|   Finance|   CA| 90000| 24|23000|\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000),\n",
    "    (\"Michael\",\"Sales\",\"NY\",86000,56,20000), \n",
    "    (\"Robert\",\"Sales\",\"CA\",81000,30,23000), \n",
    "    (\"Maria\",\"Finance\",\"CA\",90000,24,23000) \n",
    "  ]\n",
    "\n",
    "columns= [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "\n",
    "simpleData2 = [(\"James\",\"Sales\",\"NY\",90000,34,10000),\n",
    "    (\"Maria\",\"Finance\",\"CA\",90000,24,23000),\n",
    "    (\"Jen\",\"Finance\",\"NY\",79000,53,15000),\n",
    "    (\"Jeff\",\"Marketing\",\"CA\",80000,25,18000),\n",
    "    (\"Kumar\",\"Marketing\",\"NY\",91000,50,21000)\n",
    "  ]\n",
    "\n",
    "df1 = spark.createDataFrame(simpleData,schema=columns)\n",
    "df2 = spark.createDataFrame(simpleData2,schema=columns)\n",
    "\n",
    "union_df = df1.union(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "955ce0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unionByNames --> used to merge columns by names instead of positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "56b35b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project\n",
      "Gutenberg’s\n",
      "Alice’s\n",
      "Adventures\n",
      "in\n",
      "Wonderland\n",
      "Project\n",
      "Gutenberg’s\n",
      "Adventures\n",
      "in\n",
      "Wonderland\n",
      "Project\n",
      "Gutenberg’s\n"
     ]
    }
   ],
   "source": [
    "data = [\"Project Gutenberg’s\",\n",
    "        \"Alice’s Adventures in Wonderland\",\n",
    "        \"Project Gutenberg’s\",\n",
    "        \"Adventures in Wonderland\",\n",
    "        \"Project Gutenberg’s\"]\n",
    "\n",
    "rdd=spark.sparkContext.parallelize(data)\n",
    "rdd2=rdd.flatMap(lambda x: x.split(\" \"))\n",
    "\n",
    "for element in rdd2.collect():\n",
    "    print(element)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed44ce2a",
   "metadata": {},
   "source": [
    "## datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "34ffef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(\"*\").limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8536447b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------+---+-------------+-------+-------------+---------+-----------+\n",
      "|    ID|        Name|Age|  Nationality|Overall|         Club|    Value|     Joined|\n",
      "+------+------------+---+-------------+-------+-------------+---------+-----------+\n",
      "|205965|S. Ristovski| 26|FYR Macedonia|     76|  Sporting CP|750000000|Aug 8, 2017|\n",
      "|227557|M. Cassierra| 21|     Colombia|     70| FC Groningen|270000000|       null|\n",
      "|236639|        Xeka| 23|     Portugal|     73|   LOSC Lille|470000000|Jul 1, 2017|\n",
      "|131444|    R. Würtz| 34|      Denmark|     68|   Aalborg BK|   425000|Jul 9, 2009|\n",
      "|190467|  D. de Buen| 26|       Mexico|     70|Santos Laguna|180000000|Jan 1, 2016|\n",
      "+------+------------+---+-------------+-------+-------------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "22c8d27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|current_date()|\n",
      "+--------------+\n",
      "|    2022-03-14|\n",
      "+--------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(f.current_date()).show(1)    #current date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1ef96c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|to_date(Joined, m d yyyy)|\n",
      "+-------------------------+\n",
      "|                     null|\n",
      "|                     null|\n",
      "|                     null|\n",
      "|                     null|\n",
      "|                     null|\n",
      "+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(f.to_date(col(\"Joined\"),\"mm dd, yyyy\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2de46123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+\n",
      "| id|     input|\n",
      "+---+----------+\n",
      "|  1|2020-02-01|\n",
      "|  2|2019-03-01|\n",
      "|  3|2021-03-01|\n",
      "+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data=[[\"1\",\"2020-02-01\"],[\"2\",\"2019-03-01\"],[\"3\",\"2021-03-01\"]]\n",
    "df=spark.createDataFrame(data,[\"id\",\"input\"])\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "47ccec10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- input: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn(\"input\",df.input.cast(DateType()))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5d4fb927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "| current_timestamp()|\n",
      "+--------------------+\n",
      "|2022-03-14 16:49:...|\n",
      "|2022-03-14 16:49:...|\n",
      "|2022-03-14 16:49:...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(f.current_timestamp()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "18a2699d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|     input|date_format|\n",
      "+----------+-----------+\n",
      "|2020-02-01| 02-01-2020|\n",
      "|2019-03-01| 03-01-2019|\n",
      "|2021-03-01| 03-01-2021|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"input\"),f.date_format(col(\"input\"), \"MM-dd-yyyy\").alias(\"date_format\")).show() #changing format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d1f191a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n",
      "|datediff(current_date(), input)|\n",
      "+-------------------------------+\n",
      "|                            772|\n",
      "|                           1109|\n",
      "|                            378|\n",
      "+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(f.datediff(f.current_date(),col(\"input\"))).show()   #difference in date #month_between()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a26be8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+----------+----------+----------+\n",
      "|     input|add_months|sub_months|  date_add|  date_sub|\n",
      "+----------+----------+----------+----------+----------+\n",
      "|2020-02-01|2020-05-01|2019-11-01|2020-02-05|2020-01-28|\n",
      "|2019-03-01|2019-06-01|2018-12-01|2019-03-05|2019-02-25|\n",
      "|2021-03-01|2021-06-01|2020-12-01|2021-03-05|2021-02-25|\n",
      "+----------+----------+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"input\"), \n",
    "    f.add_months(col(\"input\"),3).alias(\"add_months\"), \n",
    "    f.add_months(col(\"input\"),-3).alias(\"sub_months\"), \n",
    "    f.date_add(col(\"input\"),4).alias(\"date_add\"), \n",
    "    f.date_sub(col(\"input\"),4).alias(\"date_sub\") \n",
    "  ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cf6a47f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+-----+----------+----------+\n",
      "|     input|year|month|  next_day|weekofyear|\n",
      "+----------+----+-----+----------+----------+\n",
      "|2020-02-01|2020|    2|2020-02-02|         5|\n",
      "|2019-03-01|2019|    3|2019-03-03|         9|\n",
      "|2021-03-01|2021|    3|2021-03-07|         9|\n",
      "+----------+----+-----+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"input\"), \n",
    "     f.year(col(\"input\")).alias(\"year\"), \n",
    "     f.month(col(\"input\")).alias(\"month\"), \n",
    "     f.next_day(col(\"input\"),\"Sunday\").alias(\"next_day\"), \n",
    "     f.weekofyear(col(\"input\")).alias(\"weekofyear\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ada48f",
   "metadata": {},
   "source": [
    "## User defined functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9e365715",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfU = df.select(\"*\").limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f84dee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convCase(s):\n",
    "    result = \"\"\n",
    "    for x in s.split(\" \"):\n",
    "        result+=x[0].lower() + x[1:] + \" \"\n",
    "    return result.strip()\n",
    "\n",
    "p = convCase(\"Shashank Ajgaonkar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fdf6ae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Converting function to UDF \"\"\"\n",
    "convertUDF = f.udf(lambda z: convCase(z),StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bd0138a6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+\n",
      "|    ID|    Inverted name|\n",
      "+------+-----------------+\n",
      "|158023|         l. messi|\n",
      "| 20801|cristiano ronaldo|\n",
      "|190871|        neymar jr|\n",
      "|193080|           de gea|\n",
      "|192985|     k. de bruyne|\n",
      "|183277|        e. hazard|\n",
      "|177003|        l. modrić|\n",
      "|176580|        l. suárez|\n",
      "|155862|     sergio ramos|\n",
      "|200389|         j. oblak|\n",
      "+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfU.select(\"ID\",convertUDF(\"Name\").alias(\"Inverted name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3ca53596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------------+\n",
      "|ID    |name             |\n",
      "+------+-----------------+\n",
      "|158023|l. messi         |\n",
      "|20801 |cristiano ronaldo|\n",
      "|190871|neymar jr        |\n",
      "|193080|de gea           |\n",
      "|192985|k. de bruyne     |\n",
      "|183277|e. hazard        |\n",
      "|177003|l. modrić        |\n",
      "|176580|l. suárez        |\n",
      "|155862|sergio ramos     |\n",
      "|200389|j. oblak         |\n",
      "+------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/03/15 17:01:30 WARN SimpleFunctionRegistry: The function convertudf replaced a previously registered function.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Using UDF on SQL \"\"\"\n",
    "spark.udf.register(\"convertUDF\", convCase,StringType())\n",
    "dfU.createOrReplaceTempView(\"new_view\")\n",
    "spark.sql(\"select ID, convertUDF(Name) as name from new_view\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977c9c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4298a5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd62628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b8f41e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
